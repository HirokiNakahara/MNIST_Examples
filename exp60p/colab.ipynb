{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG6-1k17Jsic",
        "colab_type": "text"
      },
      "source": [
        "<H2>手書き文字認識を行うNeural Networkのレシピ</H2><br><H3>中原作成</H3>\n",
        "ニューラルネットワークを使った画像認識のレシピです。今回はチュートリアルなどでよく使われている手書き文字データセットMNISTを学習してモデルを作成し、テスト画像を入力してその認識精度を確認します。\n",
        "\n",
        "Chainer 4.5.0<BR>\n",
        "CuPy 4.5.0<BR>\n",
        "CUDA 9.2<BR>\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kRHD0H7Qs17",
        "colab_type": "text"
      },
      "source": [
        "<H2>環境のセットアップ（TSUBAMEでは不要？)</H2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xulhz7GExHiu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check GPU status\n",
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCJdcBejxRH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install Chainer v4.5.0, Cupy v4.5.0 and CUDA\n",
        "#!curl https://colab.chainer.org/install | CHAINER_VERSION=\"==4.5.0\" CUPY_VERSION=\"==4.5.0\" sh -"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl5wlxN9ROIc",
        "colab_type": "text"
      },
      "source": [
        "<H3>必要なライブラリのインポート</H3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyGLqwsQ_h1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import training\n",
        "from chainer.training import extensions\n",
        "from chainer.dataset import concat_examples\n",
        "from chainer.backends.cuda import to_cpu\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPVtGsZDxWx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check environment\n",
        "print('GPU availability:', chainer.cuda.available)\n",
        "print('cuDNN availablility:', chainer.cuda.cudnn_enabled)\n",
        "import chainer\n",
        "chainer.print_runtime_info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBZpV4wXRWpl",
        "colab_type": "text"
      },
      "source": [
        "<H3>ニューラルネットワークの定義</H3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEyGw2vh_SO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Binary DNN (3-layers), note that, we use a mixed-precision (Binary + Float32) neural network\n",
        "# To preserve a recognition accuracy. If you want learn more, see my FPGA'18 paper!\n",
        "class MNIST(chainer.Chain):\n",
        "\n",
        "    def __init__(self,n_mid_units=100,n_out=10):\n",
        "        super(MNIST, self).__init__()\n",
        "        with self.init_scope():\n",
        "            # the size of the inputs to each layer will be inferred\n",
        "            self.l1 = L.Linear(784, n_mid_units)\n",
        "            self.l2 = L.Linear(n_mid_units, n_mid_units)\n",
        "            self.l3 = L.Linear(n_mid_units, n_out)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h1 = F.relu(self.l1(x))\n",
        "        h2 = F.relu(self.l2(h1))\n",
        "        return self.l3(h2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHoLdtgVRxz2",
        "colab_type": "text"
      },
      "source": [
        "<H3>ニューラルネットワークのパラメータと学習の設定</H3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwnj-A0wBsCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup parameters\n",
        "args_gpu=0 # 0: GPU (strongly recommendded), -1: CPU\n",
        "args_unit=100 # The number of neurons in hidden layers\n",
        "args_batchsize=100\n",
        "args_epoch=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h6RCe2NR-Pq",
        "colab_type": "text"
      },
      "source": [
        "<H3>定義したニューラルネットワークをメモリに読み込み、学習させる準備を行います。</H3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbLWEDc0xkUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Printout parameters\n",
        "print('GPU: {}'.format(args_gpu))\n",
        "print('# unit: {}'.format(args_unit))\n",
        "print('# Minibatch-size: {}'.format(args_batchsize))\n",
        "print('# epoch: {}'.format(args_epoch))\n",
        "print('')\n",
        "\n",
        "# Set up a neural network to train\n",
        "# Classifier reports softmax cross entropy loss and accuracy at every\n",
        "# iteration, which will be used by the PrintReport extension below.\n",
        "model = MNIST()\n",
        "if args_gpu >= 0:\n",
        "    # Make a specified GPU current\n",
        "    chainer.backends.cuda.get_device_from_id(args_gpu).use()\n",
        "    model.to_gpu()  # Copy the model to the GPU\n",
        "\n",
        "# Setup an optimizer\n",
        "optimizer = chainer.optimizers.Adam(alpha=0.0001)\n",
        "optimizer.setup(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-ATPqDkg575",
        "colab_type": "text"
      },
      "source": [
        "<H3>学習データであるMNISTデータセット(またはFashion MNIST)の読み込み。初回は多少時間がかかります。。</H3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F7ctZ_LgPQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the MNIST dataset\n",
        "train, test = chainer.datasets.get_mnist() # handwritten character\n",
        "# train, test = chainer.datasets.get_fashion_mnist() # fashion items\n",
        "train = chainer.datasets.SubDataset(train, 0, 36000)\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train, args_batchsize)\n",
        "test_iter = chainer.iterators.SerialIterator(test, args_batchsize,\n",
        "                                                 repeat=False, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIInqvWNMFL6",
        "colab_type": "text"
      },
      "source": [
        "<h3>ニューラルネットワークの学習を行います。GPUを用いて高速に学習ができます。</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD20htG6yUsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_epoch = args_epoch\n",
        "start_time = time.time()\n",
        "\n",
        "while train_iter.epoch < max_epoch:\n",
        "    train_accuracies = []\n",
        "    # ---------- One iteration of the training loop ----------\n",
        "    train_batch = train_iter.next()\n",
        "    image_train, target_train = concat_examples(train_batch, args_gpu)\n",
        "\n",
        "    # Calculate the prediction of the network\n",
        "    prediction_train = model(image_train)\n",
        "\n",
        "    # Calculate the loss with softmax_cross_entropy\n",
        "    loss = F.softmax_cross_entropy(prediction_train, target_train)\n",
        "    accuracy = F.accuracy(prediction_train, target_train)\n",
        "    accuracy.to_cpu()\n",
        "    train_accuracies.append(accuracy.data)\n",
        "    # Calculate the gradients in the network\n",
        "    model.cleargrads()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update all the trainable parameters\n",
        "    optimizer.update()\n",
        "    # --------------------- until here ---------------------\n",
        "\n",
        "    # Check the validation accuracy of prediction after every epoch\n",
        "    if train_iter.is_new_epoch:  # If this iteration is the final iteration of the current epoch\n",
        "\n",
        "        # Display the training loss\n",
        "        print('epoch:{:02d} train_loss:{:.04f} '.format(\n",
        "                train_iter.epoch, float(to_cpu(loss.data))), end='')\n",
        "        print('train_accuracy:{:.04f} '.format(\n",
        "            np.mean(train_accuracies)),end='')\n",
        "\n",
        "        test_losses = []\n",
        "        test_accuracies = []\n",
        "        while True:\n",
        "            test_batch = test_iter.next()\n",
        "            image_test, target_test = concat_examples(test_batch, args_gpu)\n",
        "\n",
        "            # Forward the test data\n",
        "            prediction_test = model(image_test)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss_test = F.softmax_cross_entropy(prediction_test, target_test)\n",
        "            test_losses.append(to_cpu(loss_test.data))\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            accuracy = F.accuracy(prediction_test, target_test)\n",
        "            accuracy.to_cpu()\n",
        "            test_accuracies.append(accuracy.data)\n",
        "\n",
        "            if test_iter.is_new_epoch:\n",
        "                test_iter.reset()\n",
        "                #test_iter.epoch = 0\n",
        "                #test_iter.current_position = 0\n",
        "                #test_iter.is_new_epoch = False\n",
        "                #test_iter._pushed_position = None\n",
        "                break\n",
        "\n",
        "        print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(\n",
        "                np.mean(test_losses), np.mean(test_accuracies)))\n",
        "        \n",
        "end_time = time.time()\n",
        "print(\"------------------------------------------------------------\")\n",
        "print(\"Training complete\")\n",
        "chainer.serializers.save_npz('mnist.model',model)\n",
        "\n",
        "print('accuracy:{:.04f}'.format(np.mean(test_accuracies)))\n",
        "print('time cost:{:.04f}'.format(end_time-start_time), 's')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}