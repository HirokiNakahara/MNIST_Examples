{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TutorialMNIST_Chainer_2019Jan13.ipynb のコピー",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG6-1k17Jsic",
        "colab_type": "text"
      },
      "source": [
        "<H2>手書き文字認識を行うNeural Networkのレシピ</H2><br><H3>中原作成</H3>\n",
        "ニューラルネットワークを使った画像認識のレシピです。今回はチュートリアルなどでよく使われている手書き文字データセットMNISTを学習してモデルを作成し、テスト画像を入力してその認識精度を確認します。\n",
        "\n",
        "Chainer 4.5.0<BR>\n",
        "CuPy 4.5.0<BR>\n",
        "CUDA 9.2<BR>\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kRHD0H7Qs17",
        "colab_type": "text"
      },
      "source": [
        "<H2>環境のセットアップ（TSUBAMEでは不要？)</H2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xulhz7GExHiu",
        "colab_type": "code",
        "outputId": "f5c0ffb0-9ed1-45cc-ce22-cfe6355cdad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# Check GPU status\n",
        "!nvidia-smi"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jul  1 03:44:53 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 410.79       CUDA Version: 10.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P0    28W /  70W |    467MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCJdcBejxRH1",
        "colab_type": "code",
        "outputId": "1dc2b51e-f1be-452c-ff7e-2c261b1c68b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# Install Chainer v4.5.0, Cupy v4.5.0 and CUDA\n",
        "!curl https://colab.chainer.org/install | CHAINER_VERSION=\"==4.5.0\" CUPY_VERSION=\"==4.5.0\" sh -"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1580  100  1580    0     0  16989      0 --:--:-- --:--:-- --:--:-- 16989\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "+ pip install -q cupy-cuda100 ==4.5.0 chainer ==4.5.0\n",
            "\u001b[31m  ERROR: Could not find a version that satisfies the requirement cupy-cuda100==4.5.0 (from versions: 5.1.0, 5.2.0, 5.3.0, 5.4.0, 6.0.0b1, 6.0.0b2, 6.0.0b3, 6.0.0rc1, 6.0.0, 6.1.0, 7.0.0a1, 7.0.0b1)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for cupy-cuda100==4.5.0\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zl5wlxN9ROIc",
        "colab_type": "text"
      },
      "source": [
        "<H3>必要なライブラリのインポート</H3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyGLqwsQ_h1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import libraries\n",
        "import chainer\n",
        "import chainer.functions as F\n",
        "import chainer.links as L\n",
        "from chainer import training\n",
        "from chainer.training import extensions\n",
        "from chainer.dataset import concat_examples\n",
        "from chainer.backends.cuda import to_cpu\n",
        "import numpy as np\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPVtGsZDxWx2",
        "colab_type": "code",
        "outputId": "e6ebe7a6-a21c-4e46-a14f-fa1a24ff9cb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# Check environment\n",
        "print('GPU availability:', chainer.cuda.available)\n",
        "print('cuDNN availablility:', chainer.cuda.cudnn_enabled)\n",
        "import chainer\n",
        "chainer.print_runtime_info()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU availability: True\n",
            "cuDNN availablility: True\n",
            "Platform: Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic\n",
            "Chainer: 5.4.0\n",
            "NumPy: 1.16.4\n",
            "CuPy:\n",
            "  CuPy Version          : 5.4.0\n",
            "  CUDA Root             : /usr/local/cuda\n",
            "  CUDA Build Version    : 10000\n",
            "  CUDA Driver Version   : 10000\n",
            "  CUDA Runtime Version  : 10000\n",
            "  cuDNN Build Version   : 7301\n",
            "  cuDNN Version         : 7301\n",
            "  NCCL Build Version    : 2402\n",
            "  NCCL Runtime Version  : 2402\n",
            "iDeep: 2.0.0.post3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBZpV4wXRWpl",
        "colab_type": "text"
      },
      "source": [
        "<H3>ニューラルネットワークの定義</H3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEyGw2vh_SO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Binary DNN (3-layers), note that, we use a mixed-precision (Binary + Float32) neural network\n",
        "# To preserve a recognition accuracy. If you want learn more, see my FPGA'18 paper!\n",
        "class MNIST(chainer.Chain):\n",
        "\n",
        "    def __init__(self,n_mid_units=100,n_out=10):\n",
        "        super(MNIST, self).__init__()\n",
        "        with self.init_scope():\n",
        "            # the size of the inputs to each layer will be inferred\n",
        "            self.l1 = L.Linear(784, n_mid_units)\n",
        "            self.l2 = L.Linear(n_mid_units, n_mid_units)\n",
        "            self.l3 = L.Linear(n_mid_units, n_out)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        h1 = F.relu(self.l1(x))\n",
        "        h2 = F.relu(self.l2(h1))\n",
        "        return self.l3(h2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHoLdtgVRxz2",
        "colab_type": "text"
      },
      "source": [
        "<H3>ニューラルネットワークのパラメータと学習の設定</H3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwnj-A0wBsCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup parameters\n",
        "args_gpu=0 # 0: GPU (strongly recommendded), -1: CPU\n",
        "args_unit=100 # The number of neurons in hidden layers\n",
        "args_batchsize=100\n",
        "args_epoch=3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_h6RCe2NR-Pq",
        "colab_type": "text"
      },
      "source": [
        "<H3>定義したニューラルネットワークをメモリに読み込み、学習させる準備を行います。</H3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbLWEDc0xkUR",
        "colab_type": "code",
        "outputId": "c7d5f33f-730d-4255-f4f2-e23f471af7f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Printout parameters\n",
        "print('GPU: {}'.format(args_gpu))\n",
        "print('# unit: {}'.format(args_unit))\n",
        "print('# Minibatch-size: {}'.format(args_batchsize))\n",
        "print('# epoch: {}'.format(args_epoch))\n",
        "print('')\n",
        "\n",
        "# Set up a neural network to train\n",
        "# Classifier reports softmax cross entropy loss and accuracy at every\n",
        "# iteration, which will be used by the PrintReport extension below.\n",
        "model = MNIST()\n",
        "if args_gpu >= 0:\n",
        "    # Make a specified GPU current\n",
        "    chainer.backends.cuda.get_device_from_id(args_gpu).use()\n",
        "    model.to_gpu()  # Copy the model to the GPU\n",
        "\n",
        "# Setup an optimizer\n",
        "optimizer = chainer.optimizers.Adam(alpha=0.0001)\n",
        "optimizer.setup(model)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU: 0\n",
            "# unit: 100\n",
            "# Minibatch-size: 100\n",
            "# epoch: 3\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<chainer.optimizers.adam.Adam at 0x7f12f3466390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-ATPqDkg575",
        "colab_type": "text"
      },
      "source": [
        "<H3>学習データであるMNISTデータセット(またはFashion MNIST)の読み込み。初回は多少時間がかかります。。</H3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F7ctZ_LgPQ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the MNIST dataset\n",
        "train, test = chainer.datasets.get_mnist() # handwritten character\n",
        "# train, test = chainer.datasets.get_fashion_mnist() # fashion items\n",
        "train = chainer.datasets.SubDataset(train, 0, 60000)\n",
        "\n",
        "train_iter = chainer.iterators.SerialIterator(train, args_batchsize)\n",
        "test_iter = chainer.iterators.SerialIterator(test, args_batchsize,\n",
        "                                                 repeat=False, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmi7vP0Kg_IY",
        "colab_type": "text"
      },
      "source": [
        "<H3>MNISTデータの表示。このような画像を５万枚用いて学習します。認識精度のチェックには残り１万枚を用います。</H3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIInqvWNMFL6",
        "colab_type": "text"
      },
      "source": [
        "<h3>ニューラルネットワークの学習を行います。GPUを用いて高速に学習ができます。</h3>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD20htG6yUsL",
        "colab_type": "code",
        "outputId": "9c9f876b-86ba-4052-c12a-aaa9cebc35e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "max_epoch = args_epoch\n",
        "start_time = time.time()\n",
        "\n",
        "while train_iter.epoch < max_epoch:\n",
        "    train_accuracies = []\n",
        "    # ---------- One iteration of the training loop ----------\n",
        "    train_batch = train_iter.next()\n",
        "    image_train, target_train = concat_examples(train_batch, args_gpu)\n",
        "\n",
        "    # Calculate the prediction of the network\n",
        "    prediction_train = model(image_train)\n",
        "\n",
        "    # Calculate the loss with softmax_cross_entropy\n",
        "    loss = F.softmax_cross_entropy(prediction_train, target_train)\n",
        "    accuracy = F.accuracy(prediction_train, target_train)\n",
        "    accuracy.to_cpu()\n",
        "    train_accuracies.append(accuracy.data)\n",
        "    # Calculate the gradients in the network\n",
        "    model.cleargrads()\n",
        "    loss.backward()\n",
        "\n",
        "    # Update all the trainable parameters\n",
        "    optimizer.update()\n",
        "    # --------------------- until here ---------------------\n",
        "\n",
        "    # Check the validation accuracy of prediction after every epoch\n",
        "    if train_iter.is_new_epoch:  # If this iteration is the final iteration of the current epoch\n",
        "\n",
        "        # Display the training loss\n",
        "        print('epoch:{:02d} train_loss:{:.04f} '.format(\n",
        "                train_iter.epoch, float(to_cpu(loss.data))), end='')\n",
        "        print('train_accuracy:{:.04f} '.format(\n",
        "            np.mean(train_accuracies)),end='')\n",
        "\n",
        "        test_losses = []\n",
        "        test_accuracies = []\n",
        "        while True:\n",
        "            test_batch = test_iter.next()\n",
        "            image_test, target_test = concat_examples(test_batch, args_gpu)\n",
        "\n",
        "            # Forward the test data\n",
        "            prediction_test = model(image_test)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss_test = F.softmax_cross_entropy(prediction_test, target_test)\n",
        "            test_losses.append(to_cpu(loss_test.data))\n",
        "\n",
        "            # Calculate the accuracy\n",
        "            accuracy = F.accuracy(prediction_test, target_test)\n",
        "            accuracy.to_cpu()\n",
        "            test_accuracies.append(accuracy.data)\n",
        "\n",
        "            if test_iter.is_new_epoch:\n",
        "                test_iter.epoch = 0\n",
        "                test_iter.current_position = 0\n",
        "                test_iter.is_new_epoch = False\n",
        "                test_iter._pushed_position = None\n",
        "                break\n",
        "\n",
        "        print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(\n",
        "                np.mean(test_losses), np.mean(test_accuracies)))\n",
        "        \n",
        "end_time = time.time()\n",
        "print(\"------------------------------------------------------------\")\n",
        "print(\"Training complete\")\n",
        "chainer.serializers.save_npz('mnist.model',model)\n",
        "\n",
        "print('accuracy:{:.04f}'.format(np.mean(test_accuracies)))\n",
        "print('time cost:{:.04f}'.format(end_time-start_time), 's')\n"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch:01 train_loss:0.4011 train_accuracy:0.9200 val_loss:0.3844 val_accuracy:0.9009\n",
            "epoch:02 train_loss:0.2753 train_accuracy:0.9200 val_loss:0.2825 val_accuracy:0.9200\n",
            "epoch:03 train_loss:0.3101 train_accuracy:0.9000 val_loss:0.2425 val_accuracy:0.9325\n",
            "------------------------------------------------------------\n",
            "Training complete\n",
            "accuracy:0.9325\n",
            "time cost:7.5639 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}